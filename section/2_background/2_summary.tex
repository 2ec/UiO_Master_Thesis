\section{Summary}
\label{sec:2_summary}

\begin{comment}
SUMMARY: Often, we recommend ending this chapter (and all chapters after except the conclusion) with a summary section. The aim is to give an overview of, and tea-spoon-feeding the reader with, what he/she should have learned reading this chapter. What can be concluded from this chapter? 
How does the information given here give arguments for your problem statement? Finally, lead to the next chapter (“... and we will therefore in the next chapter address these challenges, and describe our ideas/implementation/...”)
\end{comment}


This chapter provides an overview of the background and motivation for using the concept of \gls{xai} in various applications. 
The discussion focuses on the challenge of understanding decision-making processes in complex AI systems and the necessity for more transparent machine learning models, particularly in applications where the consequences of erroneous decisions can be severe. 


The chapter also delves into the history of AI and its two main paradigms: symbolic and connectionist AI. 
Moreover, it lays out various machine learning techniques, including supervised, unsupervised, and semi-supervised learning, as well as deep learning and neural networks.


The key takeaways from this chapter are:

\begin{itemize}
    \item The importance of XAI in building transparent and trustworthy AI systems for real-world applications.
    \item The diverse techniques used in machine learning, why they are used, and how they differ.
\end{itemize}

The topics discussed in this chapter provide insight into the importance of designing systems transparently. An understanding of the data and models used helps researchers build better and more appropriate systems, and users can better understand why those systems predict what they do.

\begin{comment}
    How does the information given here give arguments for your problem statement?
\end{comment}

This work will use a combination of a \gls{cnn}, an \gls{llm}, and \gls{xai} to conduct its experiments. 
These experiments will investigate further how these methods can be understood and explained. 


The following chapter will therefore introduce some methods that address some of the challenges presented in this chapter. Two different approaches are presented, and both have multimodal capabilities. Both models are based on the \gls{vqa} task, where one model uses a traditional \gls{vqa} architecture, with an explanation method that explains visual features using text. The other model also describes images using text but is based on an \gls{llm}. 
The next chapter is, therefore, a summary of methods used to answer the research goals of this thesis.