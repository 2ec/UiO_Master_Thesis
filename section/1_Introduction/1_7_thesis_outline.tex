\label{sec:1_7_thesis_outline}

\begin{comment}
Describe how you have divided your thesis into chapters, and briefly list what the reader will find in each chapter.
\end{comment}

\section{Thesis outline}

This work is divided into five main chapters.
All the references used are listed after the last chapter. 
The thesis is structured in the following way:

\begin{itemize}

    \item \textbf{Chapter 1: Introduction} - This is the introduction to this project and thesis. It is designed to be intuitive to follow and convey this research project's motivation and overall goal.
    
    \item \textbf{Chapter 2: Background} - This chapter establishes the foundation and context for the subsequent thesis chapters. It provides the necessary background knowledge and related work for understanding the research conducted in this thesis. It covers the motivation for the research, the importance of XAI, relevant technologies such as AI and machine learning, model explanation techniques, evaluation metrics, and a summary of related work in the XAI field.
    
    \item \textbf{Chapter 3: Methodology} - This chapter delves into the details of two proposed methods in this work, both aiming to explore the implementation of explanatory methods in different domains using machine learning models. The first method, FLEX-VQA, combines a \gls{vqa} architecture with the \gls{flex} framework to provide explanations originating from the visual domain translated into natural language. The second method involves an \gls{llm} combined with a \gls{cnn}, where image features are translated into text for explanation. 
    The chapter highlights the significance of these models' multimodal capabilities and discusses the specific techniques employed. The Alpaca-VQA model, chosen for its pre-training and efficiency, is fine-tuned using the LoRA technique.

    
    \item \textbf{Chapter 4: Experiments and Results} - In this chapter, the Alpaca-VQA model is tested on two different dataset sizes, starting with an investigatory experiment on a smaller dataset to gain initial insights. The model is then trained on a larger dataset of 20,000 samples, and the results are analyzed. Using explanatory post-hoc methods, such as a proxy model explained by \gls{lime} and visualizing transition scores, uncovers biases in the dataset and provides supplementary information about the model's behavior. The chapter also explores linguistic biases by testing a language-only version of the model. The key takeaway is that smaller explanatory methods can be added to larger models after training, providing valuable insights without compromising accuracy or computational resources.
    
    \item \textbf{Chapter 5: Conclusions} - This chapter concludes this thesis and summarizes the findings from the previous chapter. Limitations of the methods used are discussed, as well as future works are suggested. 

\end{itemize}


