\label{sec:1_1_background_and_motivation}

\begin{comment}
In about a page, summarize the most important background information. The text usually leads to YOUR PROBLEM STATEMENT (in the next section) and gives arguments about why this is a challenge today.
\end{comment}

\section{Background and motivation}

% Overview of XAI
\gls{xai} is both a research area and a set of techniques aimed at developing \gls{ai} methods and systems that can provide interpretable and transparent explanations for the decisions and actions of an \gls{ai}. Motivation for \gls{xai} methods arises from the increased deployment of \gls{ai} systems, especially in high-stakes domains such as finance, criminal justice, and healthcare. These domains need to trust and understand the decisions made to deploy the methods safely and ethically. Furthermore, \gls{xai} is also significant in consumer-facing systems and applications using \gls{ai} in decision-making, where users may not have the technical expertise to understand the inner workings of an \gls{ai} system.

% Dip the toes in VQA and image captioning
A specific area of \gls{xai} that has received considerable attention is natural language processing, image captioning \cite{vinyalsShowTellNeural2015, youImageCaptioningSemantic2016, vinyalsShowTellLessons2017}, and \gls{vqa}. Image captioning involves generating natural language explanations for visual input, such as images, and \gls{vqa} 
These tasks are challenging objectives as they require a deep understanding of visual and linguistic information and the combination of these modalities into insight. Explanations are most valuable when they both naturally make sense in the given context and are helpful in their respective tasks. These tasks are also closely related to human cognition, as understanding and describing visual scenes is a fundamental attribute of human perception. 

% What it can do
Research on \gls{vqa} and image captioning has important implications for a variety of applications. For example, in computer vision, \gls{vqa} and image captions can be utilized to improve object recognition and scene understanding. \gls{nlp} applications can use information in \gls{vqa} and image captions to improve machine understanding of text and images. This improvement can come from understanding modalities like vision and language to learning visual semantics that better correlate with human thinking. Through cross-modality learning, particularly in the areas of vision and language, like \gls{vqa}, improvements can be made by automating data set generation. Images can be automatically categorized, labeled, and annotated by an \gls{ai} \cite{lancasterAutomatedLabelingHuman1997, mnihMachineLearningAerial}. Models and methods can extract new knowledge about images and videos, like the semi-supervised teacher-student framework proposed by Gjestang et al. \cite{gjestangSelflearningTeacherstudentFramework2021}.
In addition, \gls{vqa} and image captions can also be applied to assistive technologies, such as helping visually impaired people understand and navigate their surroundings, or helping robots understand and react to their surroundings.

% Why it is important
The importance of \gls{xai}, \gls{vqa}, and image captions is further reinforced by recent advances in deep learning and computer vision, as these techniques have greatly improved the performance of \gls{xai} systems in these tasks. 
However, despite these advances, many challenges remain to be addressed, such as the lack of interpretability of deep neural networks and the limitations of current evaluation metrics. Solving these challenges and advancing the state of the art in \gls{xai}, \gls{vqa}, and image captioning are important research goals that can lead to significant advances in \gls{xai}.

% Summary
In summary, \gls{xai}, \gls{vqa}, and image captioning are important research areas that have many real-world applications and implications. 
These tasks are challenging and require a deep understanding of both visual and verbal information. Advances in both of these areas can lead to significant advances in \gls{ai} and \gls{xai}. Making these models more reliable and trustworthy for use in high-stakes scenarios, and more accessible to everyday users with no domain knowledge. 
Research in these areas will also benefit from advances in deep learning and computer vision. Likewise, research on interpretability issues must be done.